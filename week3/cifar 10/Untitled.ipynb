{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108fa6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "559177bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define transformation pipeline for preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image or numpy.ndarray to tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1] range\n",
    "])\n",
    "\n",
    "batch_size = 32  # Reduce batch size due to memory issues\n",
    "\n",
    "# Load CIFAR-10 dataset and create data loaders\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define classes in CIFAR-10 dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99986dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images\n",
    "def display_images(images, labels):\n",
    "    for j in range(len(images)):\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        image = images[j] / 2 + 0.5  # Unnormalize\n",
    "        npimg = image.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.title(f'Ground Truth: {classes[labels[j]]}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e772ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # 3 input channels (RGB), 6 output channels, 5x5 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Max pooling with 2x2 kernel and stride\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  # 6 input channels, 16 output channels, 5x5 kernel\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Fully connected layer: 16 * 5 * 5 input features, 120 output features\n",
    "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer: 120 input features, 84 output features\n",
    "        self.fc3 = nn.Linear(84, 10)  # Fully connected layer: 84 input features, 10 output features (classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))  # Convolution -> ReLU -> Max pooling\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))  # Convolution -> ReLU -> Max pooling\n",
    "        x = torch.flatten(x, 1)  # Flatten 2D features to 1D\n",
    "        x = nn.functional.relu(self.fc1(x))  # Fully connected -> ReLU\n",
    "        x = nn.functional.relu(self.fc2(x))  # Fully connected -> ReLU\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Create an instance of the CNN model\n",
    "model = CNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3edd881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross entropy loss function for multi-class classification\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # SGD optimizer with learning rate and momentum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32deb0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.303\n",
      "[1,   200] loss: 2.302\n",
      "[1,   300] loss: 2.300\n",
      "[1,   400] loss: 2.298\n",
      "[1,   500] loss: 2.296\n",
      "[1,   600] loss: 2.291\n",
      "[1,   700] loss: 2.285\n",
      "[1,   800] loss: 2.271\n",
      "[1,   900] loss: 2.250\n",
      "[1,  1000] loss: 2.184\n",
      "[1,  1100] loss: 2.111\n",
      "[1,  1200] loss: 2.042\n",
      "[1,  1300] loss: 2.015\n",
      "[1,  1400] loss: 1.989\n",
      "[1,  1500] loss: 1.963\n",
      "[2,   100] loss: 1.921\n",
      "[2,   200] loss: 1.919\n",
      "[2,   300] loss: 1.915\n",
      "[2,   400] loss: 1.859\n",
      "[2,   500] loss: 1.843\n",
      "[2,   600] loss: 1.825\n",
      "[2,   700] loss: 1.796\n",
      "[2,   800] loss: 1.765\n",
      "[2,   900] loss: 1.770\n",
      "[2,  1000] loss: 1.741\n",
      "[2,  1100] loss: 1.712\n",
      "[2,  1200] loss: 1.687\n",
      "[2,  1300] loss: 1.691\n",
      "[2,  1400] loss: 1.651\n",
      "[2,  1500] loss: 1.655\n",
      "[3,   100] loss: 1.616\n",
      "[3,   200] loss: 1.603\n",
      "[3,   300] loss: 1.596\n",
      "[3,   400] loss: 1.609\n",
      "[3,   500] loss: 1.587\n",
      "[3,   600] loss: 1.558\n",
      "[3,   700] loss: 1.552\n",
      "[3,   800] loss: 1.555\n",
      "[3,   900] loss: 1.541\n",
      "[3,  1000] loss: 1.535\n",
      "[3,  1100] loss: 1.537\n",
      "[3,  1200] loss: 1.559\n",
      "[3,  1300] loss: 1.546\n",
      "[3,  1400] loss: 1.510\n",
      "[3,  1500] loss: 1.509\n",
      "[4,   100] loss: 1.487\n",
      "[4,   200] loss: 1.466\n",
      "[4,   300] loss: 1.454\n",
      "[4,   400] loss: 1.464\n",
      "[4,   500] loss: 1.459\n",
      "[4,   600] loss: 1.433\n",
      "[4,   700] loss: 1.456\n",
      "[4,   800] loss: 1.460\n",
      "[4,   900] loss: 1.440\n",
      "[4,  1000] loss: 1.438\n",
      "[4,  1100] loss: 1.447\n",
      "[4,  1200] loss: 1.421\n",
      "[4,  1300] loss: 1.440\n",
      "[4,  1400] loss: 1.447\n",
      "[4,  1500] loss: 1.423\n",
      "[5,   100] loss: 1.409\n",
      "[5,   200] loss: 1.388\n",
      "[5,   300] loss: 1.371\n",
      "[5,   400] loss: 1.415\n",
      "[5,   500] loss: 1.410\n",
      "[5,   600] loss: 1.371\n",
      "[5,   700] loss: 1.417\n",
      "[5,   800] loss: 1.364\n",
      "[5,   900] loss: 1.355\n",
      "[5,  1000] loss: 1.391\n",
      "[5,  1100] loss: 1.364\n",
      "[5,  1200] loss: 1.357\n",
      "[5,  1300] loss: 1.370\n",
      "[5,  1400] loss: 1.336\n",
      "[5,  1500] loss: 1.345\n",
      "[6,   100] loss: 1.343\n",
      "[6,   200] loss: 1.348\n",
      "[6,   300] loss: 1.338\n",
      "[6,   400] loss: 1.324\n",
      "[6,   500] loss: 1.318\n",
      "[6,   600] loss: 1.281\n",
      "[6,   700] loss: 1.303\n",
      "[6,   800] loss: 1.311\n",
      "[6,   900] loss: 1.335\n",
      "[6,  1000] loss: 1.302\n",
      "[6,  1100] loss: 1.319\n",
      "[6,  1200] loss: 1.316\n",
      "[6,  1300] loss: 1.339\n",
      "[6,  1400] loss: 1.306\n",
      "[6,  1500] loss: 1.277\n",
      "[7,   100] loss: 1.263\n",
      "[7,   200] loss: 1.298\n",
      "[7,   300] loss: 1.270\n",
      "[7,   400] loss: 1.263\n",
      "[7,   500] loss: 1.247\n",
      "[7,   600] loss: 1.291\n",
      "[7,   700] loss: 1.262\n",
      "[7,   800] loss: 1.244\n",
      "[7,   900] loss: 1.238\n",
      "[7,  1000] loss: 1.283\n",
      "[7,  1100] loss: 1.261\n",
      "[7,  1200] loss: 1.258\n",
      "[7,  1300] loss: 1.242\n",
      "[7,  1400] loss: 1.250\n",
      "[7,  1500] loss: 1.247\n",
      "[8,   100] loss: 1.231\n",
      "[8,   200] loss: 1.234\n",
      "[8,   300] loss: 1.234\n",
      "[8,   400] loss: 1.244\n",
      "[8,   500] loss: 1.194\n",
      "[8,   600] loss: 1.211\n",
      "[8,   700] loss: 1.219\n",
      "[8,   800] loss: 1.221\n",
      "[8,   900] loss: 1.184\n",
      "[8,  1000] loss: 1.198\n",
      "[8,  1100] loss: 1.209\n",
      "[8,  1200] loss: 1.224\n",
      "[8,  1300] loss: 1.207\n",
      "[8,  1400] loss: 1.228\n",
      "[8,  1500] loss: 1.183\n",
      "[9,   100] loss: 1.145\n",
      "[9,   200] loss: 1.163\n",
      "[9,   300] loss: 1.179\n",
      "[9,   400] loss: 1.155\n",
      "[9,   500] loss: 1.152\n",
      "[9,   600] loss: 1.202\n",
      "[9,   700] loss: 1.207\n",
      "[9,   800] loss: 1.134\n",
      "[9,   900] loss: 1.181\n",
      "[9,  1000] loss: 1.171\n",
      "[9,  1100] loss: 1.159\n",
      "[9,  1200] loss: 1.231\n",
      "[9,  1300] loss: 1.182\n",
      "[9,  1400] loss: 1.183\n",
      "[9,  1500] loss: 1.161\n",
      "[10,   100] loss: 1.105\n",
      "[10,   200] loss: 1.136\n",
      "[10,   300] loss: 1.173\n",
      "[10,   400] loss: 1.133\n",
      "[10,   500] loss: 1.141\n",
      "[10,   600] loss: 1.117\n",
      "[10,   700] loss: 1.129\n",
      "[10,   800] loss: 1.154\n",
      "[10,   900] loss: 1.126\n",
      "[10,  1000] loss: 1.136\n",
      "[10,  1100] loss: 1.124\n",
      "[10,  1200] loss: 1.153\n",
      "[10,  1300] loss: 1.156\n",
      "[10,  1400] loss: 1.155\n",
      "[10,  1500] loss: 1.151\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 10  # Number of training epochs\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data  # Get the inputs\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "        running_loss += loss.item()  # Accumulate loss\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08df80c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 58.2 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the test dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct / total} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "367fa3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 61.8 %\n",
      "Accuracy of car : 66.7 %\n",
      "Accuracy of bird : 48.3 %\n",
      "Accuracy of cat : 39.9 %\n",
      "Accuracy of deer : 46.5 %\n",
      "Accuracy of dog : 45.6 %\n",
      "Accuracy of frog : 73.2 %\n",
      "Accuracy of horse : 57.1 %\n",
      "Accuracy of ship : 81.0 %\n",
      "Accuracy of truck : 61.9 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy per class\n",
    "class_correct = list(0. for _ in range(10))\n",
    "class_total = list(0. for _ in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):  # Iterate over actual batch size\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "# Print accuracy for each class\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print(f'Accuracy of {classes[i]} : {100 * class_correct[i] / class_total[i]} %')\n",
    "    else:\n",
    "        print(f'Accuracy of {classes[i]} : N/A (no samples)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54f7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
